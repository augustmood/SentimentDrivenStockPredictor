{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:52:22,162 - INFO - Initializing Spark session with optimized memory settings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/binmingli/spark-3.3.3-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/binmingli/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/binmingli/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9b4f627a-653b-462d-9417-6aae07a5439a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.17.0 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/5.3.2/spark-nlp_2.12-5.3.2.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.2!spark-nlp_2.12.jar (3973ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (29ms)\n",
      "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
      "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (5349ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.12.500/aws-java-sdk-s3-1.12.500.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-s3;1.12.500!aws-java-sdk-s3.jar (175ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (20ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-storage/2.20.1/google-cloud-storage-2.20.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-storage;2.20.1!google-cloud-storage.jar (52ms)\n",
      "downloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (14ms)\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-cpu_2.12/0.4.4/tensorflow-cpu_2.12-0.4.4.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4!tensorflow-cpu_2.12.jar (89331ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/onnxruntime/onnxruntime/1.17.0/onnxruntime-1.17.0.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.onnxruntime#onnxruntime;1.17.0!onnxruntime.jar (7849ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-kms/1.12.500/aws-java-sdk-kms-1.12.500.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-kms;1.12.500!aws-java-sdk-kms.jar (596ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.12.500/aws-java-sdk-core-1.12.500.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-core;1.12.500!aws-java-sdk-core.jar (172ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/jmespath-java/1.12.500/jmespath-java-1.12.500.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#jmespath-java;1.12.500!jmespath-java.jar (106ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.15/commons-codec-1.15.jar ...\n",
      "\t[SUCCESSFUL ] commons-codec#commons-codec;1.15!commons-codec.jar (40ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.13!httpclient.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar ...\n",
      "\t[SUCCESSFUL ] software.amazon.ion#ion-java;1.0.2!ion-java.jar(bundle) (48ms)\n",
      "downloading https://repo1.maven.org/maven2/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar ...\n",
      "\t[SUCCESSFUL ] joda-time#joda-time;2.8.1!joda-time.jar (51ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.13!httpcore.jar (30ms)\n",
      "downloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n",
      "\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (1733ms)\n",
      "downloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n",
      "\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (187ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#guava;31.1-jre!guava.jar(bundle) (201ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#failureaccess;1.0.1!failureaccess.jar(bundle) (12ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava!listenablefuture.jar (12ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/errorprone/error_prone_annotations/2.18.0/error_prone_annotations-2.18.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.errorprone#error_prone_annotations;2.18.0!error_prone_annotations.jar (14ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.j2objc#j2objc-annotations;1.3!j2objc-annotations.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client/1.43.0/google-http-client-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client;1.43.0!google-http-client.jar (34ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-contrib-http-util/0.31.1/opencensus-contrib-http-util-0.31.1.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-contrib-http-util;0.31.1!opencensus-contrib-http-util.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-jackson2/1.43.0/google-http-client-jackson2-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-jackson2;1.43.0!google-http-client-jackson2.jar (13ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-gson/1.43.0/google-http-client-gson-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-gson;1.43.0!google-http-client-gson.jar (107ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api-client/google-api-client/2.2.0/google-api-client-2.2.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api-client#google-api-client;2.2.0!google-api-client.jar (385ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/oauth-client/google-oauth-client/1.34.1/google-oauth-client-1.34.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.oauth-client#google-oauth-client;1.34.1!google-oauth-client.jar (33ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-apache-v2/1.43.0/google-http-client-apache-v2-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-apache-v2;1.43.0!google-http-client-apache-v2.jar (30ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/apis/google-api-services-storage/v1-rev20220705-2.0.0/google-api-services-storage-v1-rev20220705-2.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0!google-api-services-storage.jar (27ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.10.1!gson.jar (30ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core/2.12.0/google-cloud-core-2.12.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core;2.12.0!google-cloud-core.jar (97ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-context/1.53.0/grpc-context-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-context;1.53.0!grpc-context.jar (88ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auto/value/auto-value-annotations/1.10.1/auto-value-annotations-1.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auto.value#auto-value-annotations;1.10.1!auto-value-annotations.jar (85ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auto/value/auto-value/1.10.1/auto-value-1.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auto.value#auto-value;1.10.1!auto-value.jar (456ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar ...\n",
      "\t[SUCCESSFUL ] javax.annotation#javax.annotation-api;1.3.2!javax.annotation-api.jar (16ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core-http/2.12.0/google-cloud-core-http-2.12.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core-http;2.12.0!google-cloud-core-http.jar (86ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-appengine/1.43.0/google-http-client-appengine-1.43.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-appengine;1.43.0!google-http-client-appengine.jar (92ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax-httpjson/0.108.2/gax-httpjson-0.108.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax-httpjson;0.108.2!gax-httpjson.jar (171ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core-grpc/2.12.0/google-cloud-core-grpc-2.12.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core-grpc;2.12.0!google-cloud-core-grpc.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-alts/1.53.0/grpc-alts-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-alts;1.53.0!grpc-alts.jar (109ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-grpclb/1.53.0/grpc-grpclb-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-grpclb;1.53.0!grpc-grpclb.jar (24ms)\n",
      "downloading https://repo1.maven.org/maven2/org/conscrypt/conscrypt-openjdk-uber/2.5.2/conscrypt-openjdk-uber-2.5.2.jar ...\n",
      "\t[SUCCESSFUL ] org.conscrypt#conscrypt-openjdk-uber;2.5.2!conscrypt-openjdk-uber.jar (440ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-auth/1.53.0/grpc-auth-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-auth;1.53.0!grpc-auth.jar (22ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-protobuf/1.53.0/grpc-protobuf-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-protobuf;1.53.0!grpc-protobuf.jar (87ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-protobuf-lite/1.53.0/grpc-protobuf-lite-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-protobuf-lite;1.53.0!grpc-protobuf-lite.jar (87ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-core/1.53.0/grpc-core-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-core;1.53.0!grpc-core.jar (76ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax/2.23.2/gax-2.23.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax;2.23.2!gax.jar (276ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax-grpc/2.23.2/gax-grpc-2.23.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax-grpc;2.23.2!gax-grpc.jar (198ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auth/google-auth-library-credentials/1.16.0/google-auth-library-credentials-1.16.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auth#google-auth-library-credentials;1.16.0!google-auth-library-credentials.jar (85ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auth/google-auth-library-oauth2-http/1.16.0/google-auth-library-oauth2-http-1.16.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auth#google-auth-library-oauth2-http;1.16.0!google-auth-library-oauth2-http.jar (34ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/api-common/2.6.2/api-common-2.6.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#api-common;2.6.2!api-common.jar (16ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-api/0.31.1/opencensus-api-0.31.1.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-api;0.31.1!opencensus-api.jar (58ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-iam-v1/1.9.2/proto-google-iam-v1-1.9.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-iam-v1;1.9.2!proto-google-iam-v1.jar (29ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.21.12/protobuf-java-3.21.12.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.21.12!protobuf-java.jar(bundle) (132ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.21.12/protobuf-java-util-3.21.12.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.21.12!protobuf-java-util.jar(bundle) (190ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-common-protos/2.14.2/proto-google-common-protos-2.14.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-common-protos;2.14.2!proto-google-common-protos.jar (872ms)\n",
      "downloading https://repo1.maven.org/maven2/org/threeten/threetenbp/1.6.5/threetenbp-1.6.5.jar ...\n",
      "\t[SUCCESSFUL ] org.threeten#threetenbp;1.6.5!threetenbp.jar (44ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-cloud-storage-v2/2.20.1-alpha/proto-google-cloud-storage-v2-2.20.1-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha!proto-google-cloud-storage-v2.jar (154ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/grpc-google-cloud-storage-v2/2.20.1-alpha/grpc-google-cloud-storage-v2-2.20.1-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha!grpc-google-cloud-storage-v2.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/gapic-google-cloud-storage-v2/2.20.1-alpha/gapic-google-cloud-storage-v2-2.20.1-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha!gapic-google-cloud-storage-v2.jar (125ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-api/1.53.0/grpc-api-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-api;1.53.0!grpc-api.jar (28ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-stub/1.53.0/grpc-stub-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-stub;1.53.0!grpc-stub.jar (108ms)\n",
      "downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.31.0/checker-qual-3.31.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.31.0!checker-qual.jar (28ms)\n",
      "downloading https://repo1.maven.org/maven2/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar ...\n",
      "\t[SUCCESSFUL ] io.perfmark#perfmark-api;0.26.0!perfmark-api.jar (11ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar ...\n",
      "\t[SUCCESSFUL ] com.google.android#annotations;4.1.1.4!annotations.jar (12ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/mojo/animal-sniffer-annotations/1.22/animal-sniffer-annotations-1.22.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.mojo#animal-sniffer-annotations;1.22!animal-sniffer-annotations.jar (21ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-proto/0.2.0/opencensus-proto-0.2.0.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-proto;0.2.0!opencensus-proto.jar (73ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-services/1.53.0/grpc-services-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-services;1.53.0!grpc-services.jar (78ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/re2j/re2j/1.6/re2j-1.6.jar ...\n",
      "\t[SUCCESSFUL ] com.google.re2j#re2j;1.6!re2j.jar (25ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-netty-shaded/1.53.0/grpc-netty-shaded-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-netty-shaded;1.53.0!grpc-netty-shaded.jar (931ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-googleapis/1.53.0/grpc-googleapis-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-googleapis;1.53.0!grpc-googleapis.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-xds/1.53.0/grpc-xds-1.53.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-xds;1.53.0!grpc-xds.jar (1493ms)\n",
      "downloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n",
      "\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (27ms)\n",
      ":: resolution report :: resolve 26448ms :: artifacts dl 117844ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.17.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   83  |   80  |   80  |   5   ||   78  |   77  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9b4f627a-653b-462d-9417-6aae07a5439a\n",
      "\tconfs: [default]\n",
      "\t77 artifacts copied, 1 already retrieved (536387kB/409ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/05 18:54:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2024-04-05 18:54:53,024 - INFO - SparkSession initialization completed in 150.86 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, concat\n",
    "import findspark\n",
    "import logging\n",
    "import time\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "findspark.init()\n",
    "\n",
    "# Setup basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "start_time = time.time()\n",
    "def log_time_taken(start, operation):\n",
    "    end = time.time()\n",
    "    logger.info(f\"{operation} completed in {end - start:.2f} seconds\")\n",
    "\n",
    "# Start timing and log the initialization of the Spark session\n",
    "logger.info(\"Initializing Spark session with optimized memory settings\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Reddit Comment Context Builder\") \\\n",
    "    .master(\"local[*]\")  \\\n",
    "    .config(\"spark.executor.memory\", \"16g\")  \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")  \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"4096\") \\\n",
    "    .config(\"spark.driver.memoryOverhead\", \"2048\")  \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/Volumes/LaCie/wsb_archive/postgresql-42.7.3.jar\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"200M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.2\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\\\n",
    "    .getOrCreate()\n",
    "log_time_taken(start_time, \"SparkSession initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:55:17,852 - INFO - Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-04-05 18:55:17,852 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, lower\n",
    "import yfinance as yf\n",
    "import re\n",
    "\n",
    "# Define the class for simplifying company names\n",
    "class CompanyNameSimplifier:\n",
    "    def __init__(self):\n",
    "        self.suffixes = [\n",
    "            'Inc.', 'Inc', 'Corporation', 'Corp.', 'Corp', 'Company', 'Co.', 'Co', \n",
    "            'Limited', 'Ltd.', 'Ltd', 'PLC', 'NV', 'SA', 'AG', 'LLC', 'L.P.', 'LP'\n",
    "        ]\n",
    "        self.web_domains_regex = r'\\.com|\\.org|\\.net|\\.io|\\.co|\\.ai'\n",
    "\n",
    "    def simplify_company_name(self, name):\n",
    "        name = re.sub(self.web_domains_regex, '', name, flags=re.IGNORECASE)\n",
    "        for suffix in self.suffixes:\n",
    "            if name.endswith(suffix):\n",
    "                name = name.replace(suffix, '')\n",
    "                break\n",
    "        name = re.split(',| -', name)[0]\n",
    "        name = name.strip()\n",
    "        return name\n",
    "\n",
    "    def get_simplified_company_name(self, ticker):\n",
    "        company = yf.Ticker(ticker)\n",
    "        company_info = company.info\n",
    "        full_name = company_info.get('longName', '')\n",
    "        simple_name = self.simplify_company_name(full_name)\n",
    "        return simple_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the data from the WSB_context_file by ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower\n",
    "\n",
    "def filter_comments_by_ticker(df, ticker):\n",
    "    simplifier = CompanyNameSimplifier()\n",
    "    # Obtain the simplified company name for the given ticker\n",
    "    company_name = simplifier.get_simplified_company_name(ticker)\n",
    "    \n",
    "    # Convert the ticker and company name to lowercase for a case-insensitive search\n",
    "    ticker_lower = ticker.lower()\n",
    "    company_name_lower = company_name.lower()\n",
    "\n",
    "    # Filter the DataFrame for rows where the `comment_context` contains the ticker or the company name\n",
    "    # Uses `lower` function to ensure that the search is case-insensitive\n",
    "    filtered_df = df.filter(\n",
    "        lower(col(\"comment_context\")).contains(ticker_lower) | \n",
    "        lower(col(\"comment_context\")).contains(company_name_lower)\n",
    "    ).select(\"datetime_utc\", \"comment_score\", \"comment_body\")\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "ticker = 'NVDA'\n",
    "wsb_comments_with_context = spark.read.parquet(\"./wsb_comments_with_context\")\n",
    "stock_comments = filter_comments_by_ticker(wsb_comments_with_context, ticker)\n",
    "stock_comments.write.parquet('./stock_comments/{ticker}_comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark NLP Sentimental Analysis on wsb comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, explode, when, size, avg\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "class StockSentimentAnalyzer:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        self.pipeline = PretrainedPipeline('analyze_sentiment', lang='en')\n",
    "        self.spark = SparkSession.builder.appName(\"StockSentimentAnalysis\").getOrCreate()\n",
    "\n",
    "    def load_comments(self):\n",
    "        path = f\"./stock_comments/{self.ticker}_comments\"\n",
    "        self.df = self.spark.read.parquet(path)\n",
    "        return self.df\n",
    "\n",
    "    def analyze_sentiment(self):\n",
    "        # Rename column for analysis\n",
    "        df_renamed = self.df.withColumnRenamed(\"comment_body\", \"text\")\n",
    "        result = self.pipeline.transform(df_renamed)\n",
    "\n",
    "        # Select and rename the columns of interest\n",
    "        sentiment_df = result.select(\n",
    "            col(\"datetime_utc\"),\n",
    "            col(\"comment_score\"),\n",
    "            col(\"text\").alias(\"comment_body\"),\n",
    "            col(\"sentiment.result\").alias(\"comment_sentiment\")\n",
    "        )\n",
    "        return sentiment_df\n",
    "\n",
    "    def process_sentiments(self, df):\n",
    "        # Filter out rows where 'comment_sentiment' is not 'na'\n",
    "        filtered_df = df.filter(size(col(\"comment_sentiment\")) > 0)\n",
    "\n",
    "        # Explode the sentiment array\n",
    "        exploded_df = filtered_df.withColumn(\"individual_sentiment\", explode(col(\"comment_sentiment\")))\n",
    "\n",
    "        # Assign scores to sentiments\n",
    "        scored_df = exploded_df.withColumn(\"sentiment_score\",\n",
    "                                           when(col(\"individual_sentiment\") == \"positive\", 1)\n",
    "                                           .when(col(\"individual_sentiment\") == \"negative\", -1)\n",
    "                                           .otherwise(0))\n",
    "\n",
    "        # Group by and calculate average sentiment score\n",
    "        stock_sentiment = scored_df.groupBy(\"datetime_utc\", \"comment_score\", \"comment_body\").agg(avg(\"sentiment_score\").alias(\"sentiment_score\"))\n",
    "\n",
    "        return stock_sentiment.orderBy(\"datetime_utc\")\n",
    "\n",
    "    def save_sentiments(self, df):\n",
    "        path = f\"./stock_sentiments/{self.ticker}_sentiment\"\n",
    "        df.write.mode(\"overwrite\").parquet(path)\n",
    "\n",
    "    def run(self):\n",
    "        self.load_comments()\n",
    "        sentiment_df = self.analyze_sentiment()\n",
    "        processed_df = self.process_sentiments(sentiment_df)\n",
    "        self.save_sentiments(processed_df)\n",
    "        return processed_df\n",
    "\n",
    "# Example usage:\n",
    "ticker = \"NVDA\"\n",
    "analyzer = StockSentimentAnalyzer(ticker)\n",
    "stock_sentiment = analyzer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_sentiment download started this may take some time.\n",
      "Approx size to download 4.8 MB\n",
      "[OK!]\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |result                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+\n",
      "|![img](emote|t5_2th52|4259)                                                                                                                                                                                                                                                                                                                                                                                                                                                           |[positive]                                                                                |\n",
      "|This is the only correct answer in this whole fucking thread...\\n\\nRide that bitch til the wheels fall off                                                                                                                                                                                                                                                                                                                                                                            |[negative, positive]                                                                      |\n",
      "|You're also missing the point.  NVDA is making a profit, most of the other companies benefitting from the word AI are neither making a profit nor even contributing to AI (some are probably not even using it)                                                                                                                                                                                                                                                                       |[positive, negative]                                                                      |\n",
      "|![img](emote|t5_2th52|27189)                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[positive]                                                                                |\n",
      "|![img](emote|t5_2th52|4641)                                                                                                                                                                                                                                                                                                                                                                                                                                                           |[positive]                                                                                |\n",
      "|Thank you. This is literally what people mean by priced in. People are not buying a stock because it will do well tomorrow. They are buying because they are betting on the company growing over time.                                                                                                                                                                                                                                                                                |[positive, negative, negative, negative]                                                  |\n",
      "|![img](emote|t5_2th52|18632)                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[positive]                                                                                |\n",
      "|Tell me you lost money on puts without telling me you lost money on puts                                                                                                                                                                                                                                                                                                                                                                                                              |[positive]                                                                                |\n",
      "|Ah yes, nvidia has a larger market valuation than all of Berkshire-Hathaway despite generating less than 10% the total revenue lol\\n\\nNvidias 2022 total revenue, despite being a record year for them, was still less than BHs profit lol.                                                                                                                                                                                                                                           |[positive]                                                                                |\n",
      "|Maybe I’m regarded, but I bought NVDA $300P at close.                                                                                                                                                                                                                                                                                                                                                                                                                                 |[negative]                                                                                |\n",
      "|My cost basis is 50 bucks. Bought more in the 200s.                                                                                                                                                                                                                                                                                                                                                                                                                                   |[positive, positive]                                                                      |\n",
      "|Ya'll are sniffing glue?\\n\\n\\n\\n\\n\\n Can I get a hit?                                                                                                                                                                                                                                                                                                                                                                                                                                 |[negative, negative]                                                                      |\n",
      "|Everyone here is talking about NVDA has a highly regarded PE of 170 but no one bats an eye when AMD has a PE ratio of 450 🤔                                                                                                                                                                                                                                                                                                                                                          |[negative]                                                                                |\n",
      "|I'm regarded too. Got mine for 2.15 each. Probably down 50% by open lol                                                                                                                                                                                                                                                                                                                                                                                                               |[positive, positive, negative]                                                            |\n",
      "|Ya.. not looking so good haha                                                                                                                                                                                                                                                                                                                                                                                                                                                         |[negative, negative, negative]                                                            |\n",
      "|*\"Es muy bueno*\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |[na]                                                                                      |\n",
      "|> but no one bats an eye when AMD has a PE ratio of 450\\n\\nYou're probably asking the wrong people.                                                                                                                                                                                                                                                                                                                                                                                   |[negative]                                                                                |\n",
      "|Rebuttal: passive investing\\n\\n![img](emote|t5_2th52|4276)                                                                                                                                                                                                                                                                                                                                                                                                                            |[negative]                                                                                |\n",
      "|Crowning* right? U missed it, or that shall i however did.                                                                                                                                                                                                                                                                                                                                                                                                                            |[negative, negative]                                                                      |\n",
      "|I wanted to buy puts on NVDA two weeks ago, but I am glad I didn't... two weeks have gone by and I bought a few calls here and there for quick in and out trades... do I switch my bias here? Can't tell if I am fading too early.\\n\\n[https://www.reddit.com/r/wallstreetbets/comments/134zl7z/comment/jiivkfc/?utm\\_source=share&utm\\_medium=web2x&context=3](https://www.reddit.com/r/wallstreetbets/comments/134zl7z/comment/jiivkfc/?utm_source=share&utm_medium=web2x&context=3)|[positive, negative, negative, negative, negative, negative, negative, negative, positive]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------------------+-------------------+\n",
      "|       datetime_utc|comment_score|        comment_body|    sentiment_score|\n",
      "+-------------------+-------------+--------------------+-------------------+\n",
      "|2012-05-11 14:12:50|            5|You gotta get the...|               -1.0|\n",
      "|2012-05-11 15:30:06|            2|           [deleted]|                0.0|\n",
      "|2012-05-11 15:39:28|            3|           [deleted]|                0.0|\n",
      "|2012-05-11 16:07:45|            5|http://qkme.me/3p...|                0.0|\n",
      "|2012-05-11 16:08:29|           10|But r/investing i...|                0.0|\n",
      "|2012-05-11 16:14:17|            6|           [deleted]|                0.0|\n",
      "|2012-05-11 16:18:36|            2|                 lol|                1.0|\n",
      "|2012-05-11 16:18:58|            7|Hey guys! I have ...|-0.3333333333333333|\n",
      "|2012-05-11 16:22:44|            4|Care to teach me ...|                1.0|\n",
      "|2012-05-11 16:23:47|            5|           [deleted]|                0.0|\n",
      "|2012-05-11 16:24:06|            5|its pretty much j...|               -1.0|\n",
      "|2012-05-11 16:29:55|            5|The people who fo...|                1.0|\n",
      "|2012-05-11 16:35:51|            7|           [deleted]|                0.0|\n",
      "|2012-05-11 16:38:12|            3|Couldn't agree more.|               -1.0|\n",
      "|2012-05-11 16:46:24|            6|Id like to join M...|                1.0|\n",
      "|2012-05-11 16:56:38|            3|I'm working on it...| 0.3333333333333333|\n",
      "|2012-05-11 17:00:27|            3|Is there any good...|                0.0|\n",
      "|2012-05-11 17:01:43|            2|I like the sounds...|                0.5|\n",
      "|2012-05-11 17:04:50|            3|           [deleted]|                0.0|\n",
      "|2012-05-11 17:05:48|            4|Unsubscribed from...|               -0.5|\n",
      "+-------------------+-------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, when, size, avg\n",
    "\n",
    "# Load a pre-trained sentiment analysis pipeline\n",
    "ticker = 'NVDA'\n",
    "pipeline = PretrainedPipeline('analyze_sentiment', lang='en')\n",
    "df = spark.read.parquet(f\"./stock_comments/{ticker}_comments\")\n",
    "\n",
    "# Apply the sentiment analysis pipeline to the comment_body column\n",
    "df_renamed = df.withColumnRenamed(\"comment_body\", \"text\")\n",
    "result = pipeline.transform(df_renamed)\n",
    "\n",
    "# Show some columns including sentiment result\n",
    "result.select(\"text\", \"sentiment.result\").show(truncate=False)\n",
    "stock_sentiment = result.select(\n",
    "    col(\"datetime_utc\"),\n",
    "    col(\"comment_score\"),\n",
    "    col(\"text\").alias(\"comment_body\"),\n",
    "    col(\"sentiment.result\").alias(\"comment_sentiment\")\n",
    ")\n",
    "# Filter out rows where 'comment_sentiment' contains only 'na'\n",
    "filtered_df = stock_sentiment.filter(size(col(\"comment_sentiment\")) > 0)\n",
    "\n",
    "# Explode the sentiment array to work with individual sentiments\n",
    "exploded_df = filtered_df.withColumn(\"individual_sentiment\", explode(col(\"comment_sentiment\")))\n",
    "\n",
    "# Assign scores to sentiments: +1 for 'positive', -1 for 'negative', and 0 for 'na'\n",
    "scored_df = exploded_df.withColumn(\"sentiment_score\",\n",
    "                                   when(col(\"individual_sentiment\") == \"positive\", 1)\n",
    "                                   .when(col(\"individual_sentiment\") == \"negative\", -1)\n",
    "                                   .otherwise(0))\n",
    "\n",
    "# Group by original DataFrame identifiers (if necessary) and calculate average sentiment score\n",
    "# 'datetime_utc' and 'comment_score' can serve as a unique identifier for rows in 'stock_sentiment'\n",
    "stock_sentiment = scored_df.groupBy(\"datetime_utc\", \"comment_score\", \"comment_body\").agg(avg(\"sentiment_score\").alias(\"sentiment_score\"))\n",
    "\n",
    "stock_sentiment = stock_sentiment.orderBy(\"datetime_utc\")\n",
    "stock_sentiment.show()\n",
    "# stock_sentiment.write.parquet(f\"./stock_sentiments/{ticker}_sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_sentiment download started this may take some time.\n",
      "Approx size to download 4.8 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------------------+-------------------+\n",
      "|       datetime_utc|comment_score|        comment_body|    sentiment_score|\n",
      "+-------------------+-------------+--------------------+-------------------+\n",
      "|2012-05-11 14:12:50|            5|You gotta get the...|               -1.0|\n",
      "|2012-05-11 15:30:06|            2|           [deleted]|                0.0|\n",
      "|2012-05-11 15:39:28|            3|           [deleted]|                0.0|\n",
      "|2012-05-11 16:07:45|            5|http://qkme.me/3p...|                0.0|\n",
      "|2012-05-11 16:08:29|           10|But r/investing i...|                0.0|\n",
      "|2012-05-11 16:14:17|            6|           [deleted]|                0.0|\n",
      "|2012-05-11 16:18:36|            2|                 lol|                1.0|\n",
      "|2012-05-11 16:18:58|            7|Hey guys! I have ...|-0.3333333333333333|\n",
      "|2012-05-11 16:22:44|            4|Care to teach me ...|                1.0|\n",
      "|2012-05-11 16:23:47|            5|           [deleted]|                0.0|\n",
      "|2012-05-11 16:24:06|            5|its pretty much j...|               -1.0|\n",
      "|2012-05-11 16:29:55|            5|The people who fo...|                1.0|\n",
      "|2012-05-11 16:35:51|            7|           [deleted]|                0.0|\n",
      "|2012-05-11 16:38:12|            3|Couldn't agree more.|               -1.0|\n",
      "|2012-05-11 16:46:24|            6|Id like to join M...|                1.0|\n",
      "|2012-05-11 16:56:38|            3|I'm working on it...| 0.3333333333333333|\n",
      "|2012-05-11 17:00:27|            3|Is there any good...|                0.0|\n",
      "|2012-05-11 17:01:43|            2|I like the sounds...|                0.5|\n",
      "|2012-05-11 17:04:50|            3|           [deleted]|                0.0|\n",
      "|2012-05-11 17:05:48|            4|Unsubscribed from...|               -0.5|\n",
      "+-------------------+-------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, when, size, avg\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self, ticker, spark):\n",
    "        self.ticker = ticker\n",
    "        self.pipeline = PretrainedPipeline('analyze_sentiment', lang='en')\n",
    "        self.spark = spark\n",
    "\n",
    "    def analyze(self):\n",
    "        df = self.spark.read.parquet(f\"./stock_comments/{self.ticker}_comments\")\n",
    "        df_renamed = df.withColumnRenamed(\"comment_body\", \"text\")\n",
    "        result = self.pipeline.transform(df_renamed)\n",
    "\n",
    "        stock_sentiment = result.select(\n",
    "            col(\"datetime_utc\"),\n",
    "            col(\"comment_score\"),\n",
    "            col(\"text\").alias(\"comment_body\"),\n",
    "            col(\"sentiment.result\").alias(\"comment_sentiment\")\n",
    "        )\n",
    "\n",
    "        filtered_df = stock_sentiment.filter(size(col(\"comment_sentiment\")) > 0)\n",
    "        exploded_df = filtered_df.withColumn(\"individual_sentiment\", explode(col(\"comment_sentiment\")))\n",
    "\n",
    "        scored_df = exploded_df.withColumn(\"sentiment_score\",\n",
    "                                           when(col(\"individual_sentiment\") == \"positive\", 1)\n",
    "                                           .when(col(\"individual_sentiment\") == \"negative\", -1)\n",
    "                                           .otherwise(0))\n",
    "\n",
    "        stock_sentiment = scored_df.groupBy(\"datetime_utc\", \"comment_score\", \"comment_body\").agg(avg(\"sentiment_score\").alias(\"sentiment_score\"))\n",
    "        stock_sentiment = stock_sentiment.orderBy(\"datetime_utc\")\n",
    "\n",
    "        return stock_sentiment\n",
    "\n",
    "    def write_to_parquet(self, df):\n",
    "        df.write.parquet(f\"./stock_sentiments/{self.ticker}_sentiment\")\n",
    "\n",
    "# Example usage:\n",
    "analyzer = SentimentAnalyzer('NVDA', spark)\n",
    "sentiment_df = analyzer.analyze()\n",
    "analyzer.write_to_parquet(sentiment_df)\n",
    "sentiment_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the original sentimental feature score to the percentages, also join the popularity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lower\n",
    "import yfinance as yf\n",
    "import re\n",
    "\n",
    "class PopularityCalculator:\n",
    "    def __init__(self, ticker, df, simplifier):\n",
    "        self.ticker = ticker\n",
    "        self.df = df\n",
    "        self.simplifier = simplifier\n",
    "\n",
    "    def calculate_popularity(self):\n",
    "        # Convert to Eastern Time and simplify the company name\n",
    "        df = self.df.withColumn(\"datetime_et\", F.expr(\"from_utc_timestamp(datetime_utc, 'America/New_York')\"))\n",
    "        simplified_name = self.simplifier.get_simplified_company_name(self.ticker).lower()\n",
    "\n",
    "        # Filter comments by ticker or company name\n",
    "        filtered_comments = df.filter(\n",
    "            lower(col(\"comment_context\")).contains(self.ticker.lower()) |\n",
    "            lower(col(\"comment_context\")).contains(simplified_name)\n",
    "        )\n",
    "\n",
    "        # Aggregate daily mentions and total comments\n",
    "        ticker_mentions = filtered_comments.groupBy(F.to_date(\"datetime_et\").alias(\"date\")).count().withColumnRenamed(\"count\", \"ticker_mentions\")\n",
    "        total_comments = df.groupBy(F.to_date(\"datetime_et\").alias(\"date\")).count().withColumnRenamed(\"count\", \"total_comments\")\n",
    "\n",
    "        # Calculate popularity percentage and sort by date\n",
    "        popularity = ticker_mentions.join(total_comments, on=\"date\") \\\n",
    "            .withColumn(\"popularity_percentage\", F.col(\"ticker_mentions\") / F.col(\"total_comments\") * 100) \\\n",
    "            .orderBy(\"date\")\n",
    "\n",
    "        # Save the result\n",
    "        save_path = f'./stock_popularity/{self.ticker}_popularity'\n",
    "        popularity.write.mode('overwrite').parquet(save_path)\n",
    "\n",
    "        return popularity\n",
    "\n",
    "# Example usage:\n",
    "ticker = \"NVDA\"\n",
    "df = spark.read.parquet(\"./wsb_comments_with_context\")\n",
    "simplifier = CompanyNameSimplifier()\n",
    "popularity_calculator = PopularityCalculator(ticker, df, simplifier)\n",
    "stock_popularity = popularity_calculator.calculate_popularity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment as Percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------------+--------------+-------------------+------------------+-------------------+\n",
      "|      date|positive_count|neutral_count|negative_count|positive_percentage|neutral_percentage|negative_percentage|\n",
      "+----------+--------------+-------------+--------------+-------------------+------------------+-------------------+\n",
      "|2012-05-11|             9|           15|            12|               25.0| 41.66666666666667|  33.33333333333333|\n",
      "|2012-05-12|             2|            1|             3|  33.33333333333333|16.666666666666664|               50.0|\n",
      "|2012-06-18|             0|            1|             0|                0.0|             100.0|                0.0|\n",
      "|2012-08-08|             0|            1|             0|                0.0|             100.0|                0.0|\n",
      "|2012-08-09|             4|            6|             8|  22.22222222222222| 33.33333333333333|  44.44444444444444|\n",
      "|2012-08-10|             1|            2|             7|               10.0|              20.0|               70.0|\n",
      "|2012-08-13|             1|            0|             0|              100.0|               0.0|                0.0|\n",
      "|2012-08-17|             1|            1|             0|               50.0|              50.0|                0.0|\n",
      "|2012-09-18|             2|            1|             0|  66.66666666666666| 33.33333333333333|                0.0|\n",
      "|2012-09-21|             1|            0|             0|              100.0|               0.0|                0.0|\n",
      "|2012-10-08|             0|            0|             1|                0.0|               0.0|              100.0|\n",
      "|2012-10-22|             0|            1|             0|                0.0|             100.0|                0.0|\n",
      "|2012-11-12|             0|            0|             1|                0.0|               0.0|              100.0|\n",
      "|2013-02-27|             0|            0|             1|                0.0|               0.0|              100.0|\n",
      "|2013-02-28|             2|            1|             2|               40.0|              20.0|               40.0|\n",
      "|2013-03-02|             0|            0|             3|                0.0|               0.0|              100.0|\n",
      "|2013-03-10|             0|            0|             2|                0.0|               0.0|              100.0|\n",
      "|2013-03-11|             0|            0|             3|                0.0|               0.0|              100.0|\n",
      "|2013-05-28|             1|            0|             7|               12.5|               0.0|               87.5|\n",
      "|2013-05-29|             1|            2|             2|               20.0|              40.0|               40.0|\n",
      "+----------+--------------+-------------+--------------+-------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ticker = 'NVDA'\n",
    "stock_sentiment = spark.read.parquet(f'./stock_sentiments/{ticker}_sentiment')\n",
    "df = stock_sentiment\n",
    "# Function to categorize sentiment score\n",
    "def categorize_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'positive'\n",
    "    elif score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the categorization function\n",
    "df_with_sentiment_category = df.withColumn(\n",
    "    \"sentiment_category\",\n",
    "    when(df.sentiment_score > 0.05, \"positive\")\n",
    "    .when(df.sentiment_score < -0.05, \"negative\")\n",
    "    .otherwise(\"neutral\")\n",
    ")\n",
    "# Convert datetime_utc to Eastern Time (ET, covering both EST and EDT as appropriate)\n",
    "df = df_with_sentiment_category.withColumn(\"datetime_et\", F.expr(\"from_utc_timestamp(datetime_utc, 'America/New_York')\"))\n",
    "\n",
    "# Extract date from datetime_et\n",
    "df = df.withColumn(\"date\", F.to_date(\"datetime_et\"))\n",
    "\n",
    "# Group by date and calculate percentages\n",
    "result = df.groupBy(\"date\").agg(\n",
    "    F.expr(\"count(1) as total_comments\"),\n",
    "    F.sum(F.when(F.col(\"sentiment_category\") == \"positive\", 1).otherwise(0)).alias(\"positive_count\"),\n",
    "    F.sum(F.when(F.col(\"sentiment_category\") == \"neutral\", 1).otherwise(0)).alias(\"neutral_count\"),\n",
    "    F.sum(F.when(F.col(\"sentiment_category\") == \"negative\", 1).otherwise(0)).alias(\"negative_count\")\n",
    ").withColumn(\n",
    "    \"positive_percentage\", F.col(\"positive_count\") / F.col(\"total_comments\") * 100\n",
    ").withColumn(\n",
    "    \"neutral_percentage\", F.col(\"neutral_count\") / F.col(\"total_comments\") * 100\n",
    ").withColumn(\n",
    "    \"negative_percentage\", F.col(\"negative_count\") / F.col(\"total_comments\") * 100\n",
    ")\n",
    "result = result.drop(\"total_comments\")\n",
    "result = result.orderBy(\"date\")\n",
    "# Show the result\n",
    "result.show()\n",
    "# result.write.mode(\"overwrite\").parquet(f\"./stock_sentiments_percentage/{ticker}_sentiment_percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------------+--------------+-------------------+------------------+-------------------+\n",
      "|      date|positive_count|neutral_count|negative_count|positive_percentage|neutral_percentage|negative_percentage|\n",
      "+----------+--------------+-------------+--------------+-------------------+------------------+-------------------+\n",
      "|2012-05-11|             9|           15|            12|               25.0| 41.66666666666667|  33.33333333333333|\n",
      "|2012-05-12|             2|            1|             3|  33.33333333333333|16.666666666666664|               50.0|\n",
      "|2012-06-18|             0|            1|             0|                0.0|             100.0|                0.0|\n",
      "|2012-08-08|             0|            1|             0|                0.0|             100.0|                0.0|\n",
      "|2012-08-09|             4|            6|             8|  22.22222222222222| 33.33333333333333|  44.44444444444444|\n",
      "|2012-08-10|             1|            2|             7|               10.0|              20.0|               70.0|\n",
      "|2012-08-13|             1|            0|             0|              100.0|               0.0|                0.0|\n",
      "|2012-08-17|             1|            1|             0|               50.0|              50.0|                0.0|\n",
      "|2012-09-18|             2|            1|             0|  66.66666666666666| 33.33333333333333|                0.0|\n",
      "|2012-09-21|             1|            0|             0|              100.0|               0.0|                0.0|\n",
      "|2012-10-08|             0|            0|             1|                0.0|               0.0|              100.0|\n",
      "|2012-10-22|             0|            1|             0|                0.0|             100.0|                0.0|\n",
      "|2012-11-12|             0|            0|             1|                0.0|               0.0|              100.0|\n",
      "|2013-02-27|             0|            0|             1|                0.0|               0.0|              100.0|\n",
      "|2013-02-28|             2|            1|             2|               40.0|              20.0|               40.0|\n",
      "|2013-03-02|             0|            0|             3|                0.0|               0.0|              100.0|\n",
      "|2013-03-10|             0|            0|             2|                0.0|               0.0|              100.0|\n",
      "|2013-03-11|             0|            0|             3|                0.0|               0.0|              100.0|\n",
      "|2013-05-28|             1|            0|             7|               12.5|               0.0|               87.5|\n",
      "|2013-05-29|             1|            2|             2|               20.0|              40.0|               40.0|\n",
      "+----------+--------------+-------------+--------------+-------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "class StockSentimentPercentageAnalyzer:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        self.df = spark.read.parquet(f'./stock_sentiments/{ticker}_sentiment')\n",
    "\n",
    "    def categorize_sentiment(self):\n",
    "        df_with_sentiment_category = self.df.withColumn(\n",
    "            \"sentiment_category\",\n",
    "            when(self.df.sentiment_score > 0.05, \"positive\")\n",
    "            .when(self.df.sentiment_score < -0.05, \"negative\")\n",
    "            .otherwise(\"neutral\")\n",
    "        )\n",
    "        return df_with_sentiment_category\n",
    "\n",
    "    def analyze_sentiment(self):\n",
    "        df = self.categorize_sentiment()\n",
    "        df = df.withColumn(\"datetime_et\", F.expr(\"from_utc_timestamp(datetime_utc, 'America/New_York')\"))\n",
    "        df = df.withColumn(\"date\", F.to_date(\"datetime_et\"))\n",
    "\n",
    "        result = df.groupBy(\"date\").agg(\n",
    "            F.expr(\"count(1) as total_comments\"),\n",
    "            F.sum(F.when(F.col(\"sentiment_category\") == \"positive\", 1).otherwise(0)).alias(\"positive_count\"),\n",
    "            F.sum(F.when(F.col(\"sentiment_category\") == \"neutral\", 1).otherwise(0)).alias(\"neutral_count\"),\n",
    "            F.sum(F.when(F.col(\"sentiment_category\") == \"negative\", 1).otherwise(0)).alias(\"negative_count\")\n",
    "        ).withColumn(\n",
    "            \"positive_percentage\", F.col(\"positive_count\") / F.col(\"total_comments\") * 100\n",
    "        ).withColumn(\n",
    "            \"neutral_percentage\", F.col(\"neutral_count\") / F.col(\"total_comments\") * 100\n",
    "        ).withColumn(\n",
    "            \"negative_percentage\", F.col(\"negative_count\") / F.col(\"total_comments\") * 100\n",
    "        )\n",
    "\n",
    "        result = result.drop(\"total_comments\").orderBy(\"date\")\n",
    "        return result\n",
    "\n",
    "    def save_result(self, result):\n",
    "        result.write.mode('overwrite').parquet(f\"./stock_sentiments_percentage/{self.ticker}_sentiment_percentage\")\n",
    "\n",
    "# Example usage:\n",
    "analyzer = StockSentimentPercentageAnalyzer('NVDA')\n",
    "result = analyzer.analyze_sentiment()\n",
    "result.show()\n",
    "analyzer.save_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the data to get the final table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------+------------------+-----------------+\n",
      "|      date|        popularity|         positive|           neutral|         negative|\n",
      "+----------+------------------+-----------------+------------------+-----------------+\n",
      "|2012-05-11| 25.53191489361702|             25.0| 41.66666666666667|33.33333333333333|\n",
      "|2012-05-12|15.789473684210526|33.33333333333333|16.666666666666664|             50.0|\n",
      "|2012-06-18|               2.5|              0.0|             100.0|              0.0|\n",
      "|2012-08-08|2.1739130434782608|              0.0|             100.0|              0.0|\n",
      "|2012-08-09| 33.33333333333333|22.22222222222222| 33.33333333333333|44.44444444444444|\n",
      "|2012-08-10|19.607843137254903|             10.0|              20.0|             70.0|\n",
      "|2012-08-13|3.7037037037037033|            100.0|               0.0|              0.0|\n",
      "|2012-08-17| 2.898550724637681|             50.0|              50.0|              0.0|\n",
      "|2012-09-18|              25.0|66.66666666666666| 33.33333333333333|              0.0|\n",
      "|2012-09-21| 2.564102564102564|            100.0|               0.0|              0.0|\n",
      "|2012-10-08|              25.0|              0.0|               0.0|            100.0|\n",
      "|2012-10-22|              20.0|              0.0|             100.0|              0.0|\n",
      "|2012-11-12|              25.0|              0.0|               0.0|            100.0|\n",
      "|2013-02-27|              20.0|              0.0|               0.0|            100.0|\n",
      "|2013-02-28| 45.45454545454545|             40.0|              20.0|             40.0|\n",
      "|2013-03-02|              60.0|              0.0|               0.0|            100.0|\n",
      "|2013-03-10|              50.0|              0.0|               0.0|            100.0|\n",
      "|2013-03-11|              30.0|              0.0|               0.0|            100.0|\n",
      "|2013-05-28|38.095238095238095|             12.5|               0.0|             87.5|\n",
      "|2013-05-29| 17.24137931034483|             20.0|              40.0|             40.0|\n",
      "+----------+------------------+-----------------+------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "class StockDataMerger:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        self.spark = spark\n",
    "\n",
    "    def merge_data(self):\n",
    "        # Read stock popularity and sentiment percentage data\n",
    "        stock_popularity = self.spark.read.parquet(f\"./stock_popularity/{self.ticker}_popularity\")\n",
    "        stock_sentiment_percentage = self.spark.read.parquet(f\"./stock_sentiments_percentage/{self.ticker}_sentiment_percentage\")\n",
    "\n",
    "        # Inner join on date\n",
    "        stock_sentiment_and_popularity = stock_popularity.join(stock_sentiment_percentage, \"date\", \"inner\")\n",
    "\n",
    "        # Selecting and renaming the desired columns\n",
    "        stock_sentiment_and_popularity = stock_sentiment_and_popularity.select(\n",
    "            col(\"date\"),\n",
    "            col(\"popularity_percentage\").alias(\"popularity\"),\n",
    "            col(\"positive_percentage\").alias(\"positive\"),\n",
    "            col(\"neutral_percentage\").alias(\"neutral\"),\n",
    "            col(\"negative_percentage\").alias(\"negative\")\n",
    "        )\n",
    "\n",
    "        return stock_sentiment_and_popularity\n",
    "\n",
    "    def write_data(self, df):\n",
    "        df.write.mode('overwrite').parquet(f\"./stock_sentiment_and_popularity/{self.ticker}_sentiment_percentage\")\n",
    "\n",
    "# Example usage:\n",
    "merger = StockDataMerger(\"NVDA\")\n",
    "merged_data = merger.merge_data()\n",
    "merger.write_data(merged_data)\n",
    "merged_data.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
