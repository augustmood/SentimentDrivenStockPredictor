{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is for extracting posts regarding stock discussions from Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "2024-03-27 22:41:56.218105+00:00 - INFO - Fetching posts started\n",
      "2024-03-27 22:42:08.470567+00:00 - INFO - Fetching posts finished\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import timezone  # Necessary for handling time zones\n",
    "\n",
    "def fetch_posts(subreddit_name='WallStreetBets', limit=3000):\n",
    "    \"\"\"Fetch posts from a specified subreddit using PRAW and returns a DataFrame.\"\"\"\n",
    "\n",
    "    # Load Reddit app config from a YAML file\n",
    "    with open('../config/config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Initialize the Reddit instance with credentials from the config file\n",
    "    reddit = praw.Reddit(client_id=config['client_id'],\n",
    "                         client_secret=config['client_secret'],\n",
    "                         user_agent=\"my user agent\")\n",
    "\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    data = []\n",
    "\n",
    "    # Fetch the latest posts based on the limit\n",
    "    for post in subreddit.new(limit=limit):\n",
    "        post_datetime = datetime.datetime.fromtimestamp(post.created_utc, timezone.utc)\n",
    "        readable_timestamp = post_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        data.append([\n",
    "            post.title, post.score, post.id, post.url, post.num_comments,\n",
    "            post.created_utc, post.selftext, readable_timestamp\n",
    "        ])\n",
    "\n",
    "    # Return a DataFrame with the fetched post data\n",
    "    return pd.DataFrame(data, columns=['Title', 'Score', 'ID', 'URL', 'Comms_Num', 'Created', 'Body', 'Timestamp'])\n",
    "\n",
    "def read_csv_if_exists(filename):\n",
    "    \"\"\"Returns a DataFrame from a CSV file if it exists, or an empty DataFrame otherwise.\"\"\"\n",
    "    return pd.read_csv(filename) if os.path.exists(filename) else pd.DataFrame()\n",
    "\n",
    "def merge_and_deduplicate(original_df, new_df):\n",
    "    \"\"\"Merges two DataFrames, sorts by 'Datetime' and 'Body', and removes duplicate rows, keeping the last.\"\"\"\n",
    "    if original_df.empty:\n",
    "        original_df = pd.DataFrame(columns=new_df.columns)\n",
    "    elif new_df.empty:\n",
    "        new_df = pd.DataFrame(columns=original_df.columns)\n",
    "\n",
    "    combined_df = pd.concat([original_df, new_df])\n",
    "    combined_df['Datetime'] = pd.to_datetime(combined_df['Timestamp'], utc=True)\n",
    "    combined_df.sort_values(by=['Datetime', 'Body'], inplace=True)\n",
    "    combined_df.drop_duplicates(subset=['Datetime', 'Body'], keep='last', inplace=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def update_csv(subreddit_name='WallStreetBets', limit=3000):\n",
    "    comments_dir = 'posts'\n",
    "    os.makedirs(comments_dir, exist_ok=True)\n",
    "    \n",
    "    today = datetime.datetime.now(timezone.utc).date()\n",
    "    yesterday = today - datetime.timedelta(days=1)\n",
    "\n",
    "    current_csv_filename = os.path.join(comments_dir, f'{today}-wsb-posts.csv')\n",
    "    previous_csv_filename = os.path.join(comments_dir, f'{yesterday}-wsb-posts.csv')\n",
    "\n",
    "    new_posts_df = fetch_posts(subreddit_name, limit)\n",
    "\n",
    "    current_df = new_posts_df[pd.to_datetime(new_posts_df['Timestamp'], utc=True).dt.date == today]\n",
    "    previous_df_new = new_posts_df[pd.to_datetime(new_posts_df['Timestamp'], utc=True).dt.date == yesterday]\n",
    "\n",
    "    if not current_df.empty:\n",
    "        existing_df = read_csv_if_exists(current_csv_filename)\n",
    "        updated_current_df = merge_and_deduplicate(existing_df, current_df)\n",
    "        updated_current_df.to_csv(current_csv_filename, index=False)\n",
    "\n",
    "    if not previous_df_new.empty:\n",
    "        previous_df = read_csv_if_exists(previous_csv_filename)\n",
    "        updated_previous_df = merge_and_deduplicate(previous_df, previous_df_new)\n",
    "        updated_previous_df.to_csv(previous_csv_filename, index=False)\n",
    "\n",
    "def safe_update_csv(attempts=3, delay=10):\n",
    "    \"\"\"\n",
    "    Attempts to update CSV files with a specified number of retries and delay between attempts.\n",
    "\n",
    "    Parameters:\n",
    "    - attempts: Maximum number of attempts to try the operation.\n",
    "    - delay: Delay between attempts in seconds.\n",
    "    \"\"\"\n",
    "    for attempt in range(1, attempts + 1):\n",
    "        try:\n",
    "            print(f\"{datetime.datetime.now(timezone.utc)} - INFO - Attempt {attempt}: Fetching posts started\")\n",
    "            \n",
    "            # Perform the update operation\n",
    "            update_csv()\n",
    "\n",
    "            print(f\"{datetime.datetime.now(timezone.utc)} - INFO - Fetching posts finished successfully\")\n",
    "            return  # Exit the function upon success\n",
    "        except Exception as e:\n",
    "            print(f\"{datetime.datetime.now(timezone.utc)} - ERROR - Attempt {attempt}: failed with error: {e}\")\n",
    "            \n",
    "            if attempt == attempts:\n",
    "                print(f\"{datetime.datetime.now(timezone.utc)} - INFO - Maximum attempts reached. Exiting.\")\n",
    "                break  # Exit the loop after the last attempt\n",
    "\n",
    "            print(f\"{datetime.datetime.now(timezone.utc)} - INFO - Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('-' * 100)\n",
    "    \n",
    "    # Change the working directory to the script's directory\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.chdir(script_dir)\n",
    "    \n",
    "    # Encapsulate the retry logic in a function call for clarity and reusability\n",
    "    safe_update_csv(attempts=3, delay=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
